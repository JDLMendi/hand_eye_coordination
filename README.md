# VR Hand-Eye Coordination

**THIS PROJECT IS STILL WORK IN PROGRESS**
 
This project is a personal research project of mine. This looks at the idea of recognition between true, fake, and neutral targets using visual cues and hand-eye tracking implementation to provide feedback within Virtual Reality. 

This is deeply inspired by the idea of Military training where personal must identify between friendly and foe, reacting as quickly as they could and maximise their score by avoiding friendly and targeting foes. In addition, I am hoping to looking how partial-obstruction to vision (such as blocking one eye, partially obscuring, lighting, etc.) could impact the rate at which the user must make a decision.

The idea of this experiment is that a user is placed in front of a grid of 4x4 dots, throughout the experiment three sets of colours would appear (red - fake, green - true, gray - neutral). The user must pinch the only green dot within a specific timEframe before it moves to the next set whiles avoiding the red dots. After each phase, an obstruction is introduced and the experiment repeats again until satisfied.

The Eye-Tracking project from my FYP brought a bit of inspiration on how vision plays a role in our decision making, what happens if we alter our vision in a quick decision base making task?

_Neuroscience plays a role in how information is processed, and Vision plays a role on how we gather information._

